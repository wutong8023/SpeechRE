# @package _global_

common:
  seed: 2
  user_dir: ${env:IWSLT_ROOT}/fairseq_modules/
  tensorboard_logdir: ${env:SAVE_DIR}/lna_ed_adapt_conll04/tb_logs/
  fp16: True
  memory_efficient_fp16: True

task:
  _name: speech_to_text_iwslt21
  data: ${env:DATA_ROOT}
  max_source_positions: 400_000   # 25s @ 16kHz
  max_target_positions: 1024
  normalize: True
  da_p_augm: 0.8
  da_tempo: 0.85,1.3
  da_pitch: -300,300
  da_echo_delay: 20,200
  da_echo_decay: 0.05,0.2
  sample_ratios: 1

distributed_training:
  find_unused_parameters: True

dataset:
  train_subset: train_conll04
  valid_subset: dev_conll04
  num_workers: 4
  max_tokens: 480_000             # 30s @ 16kHz
  batch_size: 8
  required_batch_size_multiple: 1
  max_tokens_valid: 960_000
  skip_invalid_size_inputs_valid_test: True

criterion:
  _name: label_smoothed_cross_entropy
  label_smoothing: 0.2
  ignore_prefix_size: 1

checkpoint:
  save_dir: ${env:SAVE_DIR}/lna_ed_adapt_conll04/ckpts/
  save_interval_updates: 500
  keep_interval_updates: 10
  keep_best_checkpoints: 5

optimization:
  lr: [1e-04]
  max_update: 22704               # ~16 epochs
  update_freq: [16]
  sentence_avg: True
  clip_norm: 20.0

optimizer:
    _name: adam
    adam_betas: (0.9,0.98)
    adam_eps: 1e-08

lr_scheduler:
    _name: tri_stage
    phase_ratio: [0.15, 0.15, 0.7]
    init_lr_scale: 0.01
    final_lr_scale: 0.01

model:
  _name: wav2vec_seq2seq_iwslt21

  freeze_layers: encoder.feat_extr,encoder.ffn,decoder.embedding,decoder.self_attn,decoder.ffn

  w2v_path: ${env:WAV2VEC_ROOT}/wav2vec_vox_960h_pl.pt
  load_pretrained_decoder_from: ${env:MBART_ROOT}/model.pt
  autoregressive: True
  feature_grad_mult: 0.0

  apply_mask: True
  mask_prob: 0.2
  mask_channel_prob: 0.1
  mask_channel_length: 64

  dropout: 0.0
  attention_dropout: 0.1
  activation_dropout: 0.0
  final_dropout: 0.1
  layerdrop: 0.0

  adapter_dim: 4096
  adapter_dropout: 0.1

  len_adaptor_kernel_sizes: 3,3,3
  len_adaptor_channels: 1024

  decoder_embed_dim: 1024
  decoder_output_dim: 1024
  decoder_ffn_embed_dim: 4096
  decoder_layers: 12
  decoder_attention_heads: 16
  decoder_learned_pos: True
  decoder_normalize_before: True
  decoder_dropout: 0.0
  decoder_attention_dropout: 0.0
  decoder_enc_attention_dropout: 0.1
  decoder_activation_dropout: 0.0
  share_decoder_input_output_embed: True
  max_target_positions: "${task.max_target_positions}"

hydra:
  run:
    dir: ${env:SAVE_DIR}/lna_ed_adapt_conll04/hydra_outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${env:SAVE_DIR}/lna_ed_adapt_conll04/hydra_multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
